{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "# Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib \n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(history):\n",
    "    '''\n",
    "    Plots the training and validation accuracy and loss curves for fitted keras models\n",
    "    In: The history object of a trained keras model\n",
    "    Out: 2 Plots (Accuracy & Loss)\n",
    "    '''\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))  \n",
    "    fig.suptitle('Model Performance')\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Training and Validation Accuracy')\n",
    "    ax1.set(xlabel='Epoch', ylabel='Accuracy')    \n",
    "    ax1.legend(['Training Accuracy', 'Validation Accuracy'], loc='best')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Training and Validation Loss')\n",
    "    ax2.set(xlabel='Epoch', ylabel='Loss') \n",
    "    ax2.legend(['Training Loss', 'Validation Loss'], loc='best')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_conf_mat(model, load=False, load_loc=None, class_lst = 'Angry Disgust Fear Happy Sad Surprise Neutral', out='model_weights/finalconf.png'):\n",
    "    import seaborn as sns\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import math\n",
    "    # 0=angry, 1=disgust,2=fear,3=happy, 4=sad, 5=surprise, 6=neutral\n",
    "    classes = class_lst.split(' ')\n",
    "    \n",
    "    number_of_examples = len(validation_generator.filenames)\n",
    "    number_of_generator_calls = math.ceil(number_of_examples / (1.0 * batch_size)) \n",
    "    # 1.0 above is to skip integer division\n",
    "    y_true = []\n",
    "    for i in range(0,int(number_of_generator_calls)):\n",
    "        y_true.extend(np.array(validation_generator[i][1]))\n",
    "        \n",
    "    print(len(y_true))\n",
    "    print('ones', sum(y_true))\n",
    "    #y_true=[np.argmax(x) for x in val_data[1]]\n",
    "\n",
    "    if load:\n",
    "        model.load_weights(load_loc)\n",
    "        mod_name = load_loc.split('-')[0]\n",
    "    else:\n",
    "        mod_name=out\n",
    "\n",
    "        \n",
    "    val_data = []\n",
    "    for i in range(0,int(number_of_generator_calls)):\n",
    "        val_data.extend(np.array(validation_generator[i][0]))\n",
    "    \n",
    "    val_data = np.array(val_data)\n",
    "    \n",
    "    print('Prediction Time')\n",
    "    y_pred=np.argmax(model.predict(val_data),axis=1)\n",
    "    \n",
    "    \n",
    "    con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()\n",
    "\n",
    "    con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                         index = classes, \n",
    "                         columns = classes)\n",
    "\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    ax = sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.BuGn)\n",
    "    ax.set_ylim(len(classes),0)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.gcf().subplots_adjust(bottom=0.15, left=0.15)\n",
    "    plt.savefig(mod_name+'_performance.png')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Parameter Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "image_width, image_height = 128, 128\n",
    "image_size=(image_width, image_height)\n",
    "num_classes = 2\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "dataset_name = 'gender'\n",
    "\n",
    "patience = 20\n",
    "input_shape = (image_width, image_height, 3)\n",
    "if input_shape[2] == 1:\n",
    "    grayscale = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_data_dir = '../data/gender/train/'\n",
    "validation_data_dir = '../data/gender/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def count_num_files(root=None):\n",
    "    import os\n",
    "    count=0\n",
    "    for path, subdirs, files in os.walk(root):\n",
    "        for name in files:\n",
    "            count+=1\n",
    "        \n",
    "    return count\n",
    "\n",
    "nb_train_samples = count_num_files('data/dataset/gender/train/')\n",
    "nb_validation_samples = count_num_files('data/dataset/gender/test/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#ImageDataGenerator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## MODEL: Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# simple cnn\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(7, 7), padding='same',\n",
    "                        name='image_array', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=16, kernel_size=(7, 7), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(\n",
    "    filters=num_classes, kernel_size=(3, 3), padding='same'))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax', name='predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# simple callbacks\n",
    "log_file_path = 'logs/' + dataset_name + '_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "\n",
    "trained_models_path = 'model_weights/' + dataset_name + '_simple_CNN'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# fig = plot_conf_mat(model, load=True, load_loc='gender_models_trained/simple_CNN.81-0.96.hdf5', \n",
    "#               class_lst = 'Female Male', \n",
    "#               out='model_weights/finalconf_simplecnn.png')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "history_simpleCNN = model.fit(train_generator, steps_per_epoch=nb_train_samples // batch_size, \n",
    "                                 epochs=num_epochs, validation_data=validation_generator, \n",
    "                                 validation_steps=nb_validation_samples // batch_size, verbose=1,\n",
    "                                 callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = plot_loss_acc(history_simpleCNN)\n",
    "fig.savefig('simpleCNN.gender.losscurve.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## MODEL: mini XCEPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# mini XCEPTION callbacks\n",
    "log_file_path = '../models/logs/' + dataset_name + '_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "\n",
    "trained_models_path = '../models/weights/gender/' + dataset_name + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#mini_XCEPTION\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import SeparableConv2D, MaxPooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "l2_regularization=0.01\n",
    "\n",
    "regularization = l2(l2_regularization)\n",
    "\n",
    "# base\n",
    "img_input = Input(input_shape)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "           use_bias=False)(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "           use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# module 1\n",
    "residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "\n",
    "# module 2\n",
    "residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "\n",
    "# module 3\n",
    "residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "\n",
    "# module 4\n",
    "residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "\n",
    "x = Conv2D(num_classes, (3, 3),\n",
    "           # kernel_regularizer=regularization,\n",
    "           padding='same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Activation('softmax', name='predictions')(x)\n",
    "\n",
    "model = Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "history_mini_Xception = model.fit(train_generator, steps_per_epoch=nb_train_samples // batch_size, \n",
    "                                 epochs=num_epochs, validation_data=validation_generator, \n",
    "                                 validation_steps=nb_validation_samples // batch_size, verbose=1,\n",
    "                                 callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# fig = plot_conf_mat(model, load=True, load_loc='gender_models_trained/gender_mini_XCEPTION.21-0.95.hdf5', \n",
    "#               class_lst = 'Female Male', \n",
    "#               out='model_weights/finalconf_genderxecption.png')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = plot_loss_acc(history_mini_Xception)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## MODEL: ResNet50 Finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_data_dir = 'data/gender/train/'\n",
    "validation_data_dir = 'data/gender/test/'\n",
    "nb_train_samples = 171098 #count_num_files('data/dataset/gender/train/')\n",
    "nb_validation_samples = 53742 #count_num_files('data/dataset/gender/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "image_size=(64, 64)\n",
    "image_width, image_height = 64, 64\n",
    "num_classes = 2\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "dataset_name = 'imdb'\n",
    "validation_split = .1\n",
    "\n",
    "# if K.image_data_format() == 'channels_first':\n",
    "#     input_shape = (1, image_width, image_height)\n",
    "# else:\n",
    "#     input_shape = (image_width, image_height, 1)\n",
    "\n",
    "\n",
    "do_random_crop = False\n",
    "patience = 100\n",
    "dataset_name = 'imdb'\n",
    "input_shape = (64, 64, 3)\n",
    "if input_shape[2] == 1:\n",
    "    grayscale = True\n",
    "    \n",
    "images_path = 'data/imdb_crop/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#import tensorflow_hub as hub\n",
    "print(\"TF version:\", tf.__version__)\n",
    "#print(\"Hub version:\", hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "                        rescale=1. / 255,\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        #width_shift_range=0.1,\n",
    "                        #height_shift_range=0.1,\n",
    "                        #zoom_range=.1,\n",
    "                        horizontal_flip=True,\n",
    "                        preprocessing_function = preprocess_input)\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "top_model_weights_path = '../bottleneck_fc_model.h5'\n",
    "\n",
    "#from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2 \n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "import numpy as np\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# build the resnet50 network\n",
    "base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(64,64,3))\n",
    "print('Model loaded.')\n",
    "\n",
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(512, activation='relu'))\n",
    "top_model.add(Dropout(0.3))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.3))\n",
    "top_model.add(Dense(128, activation='relu'))\n",
    "top_model.add(Dropout(0.3))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(len(base_model.layers))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "#top_model.load_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# resnet summary\n",
    "# base_model.summary()\n",
    "# i=0\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "#     i = i+1\n",
    "#     print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "# other models use this\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "# add the model on top of the convolutional base\n",
    "model.add(top_model)\n",
    "\n",
    "\n",
    "# set the first 170 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "\n",
    "\n",
    "    \n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=5e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#callbacks\n",
    "log_file_path = 'logs/' + dataset_name + '_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "\n",
    "trained_models_path = 'model_weights_gender_resnet/' + dataset_name + '_resnet50_finetune'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# model.trainable=True\n",
    "\n",
    "len(model.trainable_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#fit\n",
    "resnet_finetune = model.fit(train_generator, steps_per_epoch=nb_train_samples // batch_size, \n",
    "                                 epochs=num_epochs, validation_data=validation_generator, \n",
    "                                 validation_steps=nb_validation_samples // batch_size, verbose=1,\n",
    "                                 callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# resnet sample code to test\n",
    "# img_path = '1280px-African_Bush_Elephant.jpg'\n",
    "# img = image.load_img(img_path, target_size=(224, 224))\n",
    "# x = image.img_to_array(img)\n",
    "# x = np.expand_dims(x, axis=0)\n",
    "# x = preprocess_input(x)\n",
    "\n",
    "# preds = model.predict(x)\n",
    "# # decode the results into a list of tuples (class, description, probability)\n",
    "# # (one such list for each sample in the batch)\n",
    "# print('Predicted:', decode_predictions(preds, top=3)[0])\n",
    "# # Predicted: [(u'n02504013', u'Indian_elephant', 0.82658225), (u'n01871265', u'tusker', 0.1122357), (u'n02504458', u'African_elephant', 0.061040461)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## MODEL: ResNet50 Bottlenecked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "!pip install \"tensorflow_hub>=0.6.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#import tensorflow_hub as hub\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "#print(\"Hub version:\", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "                        rescale=1. / 255,\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        #width_shift_range=0.1,\n",
    "                        #height_shift_range=0.1,\n",
    "                        #zoom_range=.1,\n",
    "                        horizontal_flip=True,\n",
    "                        preprocessing_function = preprocess_input)\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(image_width, image_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "top_model_weights_path = '../bottleneck_fc_model.h5'\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "\n",
    "# build the resnet50 network\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64,64,3))\n",
    "print('Model loaded.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bottleneck_features_train = base_model.predict(\n",
    "    train_generator, steps=nb_train_samples // batch_size)\n",
    "#np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bottleneck_features_validation = base_model.predict(\n",
    "    validation_generator, steps=nb_validation_samples // batch_size)\n",
    "#np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# resnet summary\n",
    "# base_model.summary()\n",
    "# i=0\n",
    "# for layer in base_model.layers:\n",
    "#     layer.trainable = False\n",
    "#     i = i+1\n",
    "#     print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=5e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#callbacks\n",
    "log_file_path = 'logs/' + dataset_name + '_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "\n",
    "trained_models_path = 'model_weights_gender_resnet/' + dataset_name + '_resnet50_finetune'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# model.trainable=True\n",
    "\n",
    "len(model.trainable_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#fit\n",
    "resnet_finetune = model.fit(train_generator, steps_per_epoch=nb_train_samples // batch_size, \n",
    "                                 epochs=num_epochs, validation_data=validation_generator, \n",
    "                                 validation_steps=nb_validation_samples // batch_size, verbose=1,\n",
    "                                 callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
