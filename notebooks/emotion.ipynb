{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib \n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def plot_loss_acc(history):\n",
    "    '''\n",
    "    Plots the training and validation accuracy and loss curves for fitted keras models\n",
    "    In: The history object of a trained keras model\n",
    "    Out: 2 Plots (Accuracy & Loss)\n",
    "    '''\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))  \n",
    "    fig.suptitle('Model Performance')\n",
    "\n",
    "    # summarize history for accuracy\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Training and Validation Accuracy')\n",
    "    ax1.set(xlabel='Epoch', ylabel='Accuracy')    \n",
    "    ax1.legend(['Training Accuracy', 'Validation Accuracy'], loc='best')\n",
    "    \n",
    "    # summarize history for loss\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Training and Validation Loss')\n",
    "    ax2.set(xlabel='Epoch', ylabel='Loss') \n",
    "    ax2.legend(['Training Loss', 'Validation Loss'], loc='best')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_conf_mat(model, load=False, load_loc=None, class_lst = 'Angry Disgust Fear Happy Sad Surprise Neutral', out='model_weights/finalconf.png'):\n",
    "    import seaborn as sns\n",
    "    # 0=angry, 1=disgust,2=fear,3=happy, 4=sad, 5=surprise, 6=neutral\n",
    "    classes = class_lst.split(' ')\n",
    "    y_true=[np.argmax(x) for x in val_data[1]]\n",
    "\n",
    "    if load:\n",
    "        model.load_weights(load_loc)\n",
    "        mod_name = load_loc.split('-')[0]\n",
    "    else:\n",
    "        mod_name=out\n",
    "\n",
    "\n",
    "    y_pred=np.argmax(model.predict(val_data),axis=1) \n",
    "    con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()\n",
    "\n",
    "    con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                         index = classes, \n",
    "                         columns = classes)\n",
    "\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    ax = sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.BuGn)\n",
    "    ax.set_ylim(len(classes),0)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.gcf().subplots_adjust(bottom=0.15, left=0.15)\n",
    "    plt.savefig(mod_name+'_performance.png')\n",
    "    return figure\n",
    "\n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 4.0 #was 2.0\n",
    "    return x\n",
    "\n",
    "def split_data(x, y, validation_split=.2):\n",
    "    num_samples = len(x)\n",
    "    num_train_samples = int((1 - validation_split)*num_samples)\n",
    "    train_x = x[:num_train_samples]\n",
    "    train_y = y[:num_train_samples]\n",
    "    val_x = x[num_train_samples:]\n",
    "    val_y = y[num_train_samples:]\n",
    "    train_data = (train_x, train_y)\n",
    "    val_data = (val_x, val_y)\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense,\\\n",
    "Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, SeparableConv2D,\\\n",
    "GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Parameter Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "image_size=(48, 48)\n",
    "image_width, image_height = 48, 48\n",
    "num_classes = 7\n",
    "\n",
    "# train_data_dir = 'FERPlus-master/data/FER2013Train'\n",
    "# validation_data_dir = 'FERPlus-master/data/FER2013Valid'\n",
    "nb_train_samples = 28559\n",
    "nb_validation_samples = 3580 \n",
    "num_epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "dataset_name = 'emotion'\n",
    "patience = 50\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (1, image_width, image_height)\n",
    "else:\n",
    "    input_shape = (image_width, image_height, 1)\n",
    "    \n",
    "img_input = Input(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# FER2013 --\n",
    "\n",
    "raw_df = pd.read_csv('../data/fer2013_and_plus.csv')\n",
    "pixels = raw_df['pixels'].tolist()\n",
    "faces = []\n",
    "for pixel_sequence in pixels:\n",
    "    face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "    face = np.asarray(face).reshape(image_width, image_height)\n",
    "    face = cv2.resize(face.astype('uint8'), image_size)\n",
    "    faces.append(face.astype('float32'))\n",
    "faces = np.asarray(faces)\n",
    "faces = np.expand_dims(faces, -1)\n",
    "emotions = pd.get_dummies(raw_df[dataset_name]).as_matrix()\n",
    "\n",
    "faces = preprocess_input(faces)\n",
    "num_samples, num_classes = emotions.shape\n",
    "train_data, val_data = split_data(faces, emotions, validation_split=0.2)\n",
    "train_faces, train_emotions = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_data[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Set Up Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "                        #rescale=1. / 255,\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator()#rescale=1. / 255)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Set Up Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### MODEL: big XCEPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#big XCEPTION\n",
    "x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n",
    "x = BatchNormalization(name='block1_conv1_bn')(x)\n",
    "x = Activation('relu', name='block1_conv1_act')(x)\n",
    "x = Conv2D(64, (3, 3), use_bias=False)(x)\n",
    "x = BatchNormalization(name='block1_conv2_bn')(x)\n",
    "x = Activation('relu', name='block1_conv2_act')(x)\n",
    "\n",
    "residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
    "x = BatchNormalization(name='block2_sepconv1_bn')(x)\n",
    "x = Activation('relu', name='block2_sepconv2_act')(x)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
    "x = BatchNormalization(name='block2_sepconv2_bn')(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "\n",
    "residual = Conv2D(256, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = Activation('relu', name='block3_sepconv1_act')(x)\n",
    "x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
    "x = BatchNormalization(name='block3_sepconv1_bn')(x)\n",
    "x = Activation('relu', name='block3_sepconv2_act')(x)\n",
    "x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
    "x = BatchNormalization(name='block3_sepconv2_bn')(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "x = Conv2D(num_classes, (3, 3),\n",
    "           # kernel_regularizer=regularization,\n",
    "           padding='same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Activation('softmax', name='predictions')(x)\n",
    "\n",
    "model = Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# big XCEPTION callbacks\n",
    "log_file_path = '../models/logs/' + dataset_name + '_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "\n",
    "trained_models_path = '../models/weights/emotion/' + dataset_name + '_big_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "history_bigXception = model.fit_generator(data_generator.flow(train_faces, train_emotions,batch_size),\n",
    "                    steps_per_epoch=len(train_faces) / batch_size,\n",
    "                    epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                    validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = plot_loss_acc(history_bigXception)\n",
    "#fig.savefig('model_weights/big XCEPTION curves')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "file_lst = sorted(glob('model_weights/emotion_mini_XCEPTION*.hdf5'))\n",
    "best_acc=0\n",
    "for i,filename in enumerate(file_lst):\n",
    "    if int(filename.split('.')[-2])>best_acc:\n",
    "        best_acc = int(filename.split('.')[-2])\n",
    "        best_idx=i\n",
    "best_loc = file_lst[best_idx]\n",
    "best_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# fig = plot_conf_mat(model, load=True, load_loc='./model_weights/emotion_big_XCEPTION.28-0.64.hdf5', \n",
    "#               class_lst = 'Angry Disgust Fear Happy Sad Surprise Neutral', out='model_weights/finalconf.png')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### MODEL: mini XCEPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#mini_XCEPTION\n",
    "from tensorflow.keras.regularizers import l2\n",
    "l2_regularization=0.06\n",
    "\n",
    "regularization = l2(l2_regularization)\n",
    "\n",
    "# base\n",
    "img_input = Input(input_shape)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "           use_bias=False)(img_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "           use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "# module 1\n",
    "residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "\n",
    "# module 2\n",
    "residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "\n",
    "# module 3\n",
    "residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "\n",
    "# module 4\n",
    "residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                  padding='same', use_bias=False)(x)\n",
    "residual = BatchNormalization()(residual)\n",
    "\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                    kernel_regularizer=regularization,\n",
    "                    use_bias=False)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "x = layers.add([x, residual])\n",
    "\n",
    "x = Conv2D(num_classes, (3, 3),\n",
    "           # kernel_regularizer=regularization,\n",
    "           padding='same')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output = Activation('softmax', name='predictions')(x)\n",
    "\n",
    "model = Model(img_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# mini XCEPTION callbacks\n",
    "log_file_path = '../models/logs/' + dataset_name + '_training_mini_xception.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1, patience=int(patience/4), verbose=1)\n",
    "\n",
    "trained_models_path = '../models/weights/emotion/' + dataset_name + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "history_miniXception = model.fit_generator(data_generator.flow(train_faces, train_emotions,batch_size),\n",
    "                    steps_per_epoch=len(train_faces) / batch_size,\n",
    "                    epochs=num_epochs, verbose=1,\n",
    "                    validation_data=val_data, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.save_weights('final_weights_emotion.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = plot_loss_acc(history_miniXception)\n",
    "fig.savefig('../models/emotion/miniXception_curves.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "file_lst = sorted(glob('../models/weights/emotion/emotion_mini_XCEPTION*.hdf5'))\n",
    "best_acc=0\n",
    "best_idx=0\n",
    "for i,filename in enumerate(file_lst):\n",
    "    plot_conf_mat(model, load=True, load_loc=filename, \n",
    "              class_lst = 'Angry Disgust Fear Happy Sad Surprise Neutral', \n",
    "              out='model_weights/finalconf.png')\n",
    "    if int(filename.split('.')[-2])>best_acc:\n",
    "        best_acc = int(filename.split('.')[-2])\n",
    "        best_idx=i\n",
    "best_loc = file_lst[best_idx]\n",
    "best_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fig = plot_conf_mat(model, load=True, load_loc=best_loc, \n",
    "              class_lst = 'Angry Disgust Fear Happy Sad Surprise Neutral', \n",
    "              out='../models/emotion_conf.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
